# Spoken Language Detection

A deep learning project for classifying spoken languages from audio clips using PyTorch. This model can distinguish between German, English, Spanish, French, Dutch, and Portuguese spoken languages.

## Project Overview

This project implements a Convolutional Neural Network (CNN) to classify audio clips of spoken languages. The model processes 5-second audio clips sampled at 8kHz and predicts which of six European languages is being spoken.

### Supported Languages
- German (de)
- English (en) 
- Spanish (es)
- French (fr)
- Dutch (nl)
- Portuguese (pt)

## Architecture

The model uses a CNN architecture with:
- 4 convolutional layers with increasing filters (32 â†’ 64 â†’ 128 â†’ 256)
- MaxPooling layers for dimensionality reduction
- Adaptive average pooling for handling variable input lengths
- Fully connected layers with dropout for classification
- Final output: 6 classes (one per language)

**Model Size:** ~100K parameters (efficient and lightweight)

## Performance

- **Test Accuracy:** ~50-60% on 6-class classification
- **Binary Classification:** 80%+ accuracy (English vs Spanish)
- **Training:** 60 epochs with Adam optimizer

## ğŸš€ Quick Start

### Prerequisites

```bash
python >= 3.8
torch >= 1.9.0
numpy
matplotlib
seaborn
pandas
```

### Installation

1. Clone the repository:
```bash
git clone https://github.com/yourusername/spoken-lang-detect.git
cd spoken-lang-detect
```

2. Install dependencies:
```bash
pip install -r requirements.txt
``

### Usage

#### Training a new model:
```bash
python scripts/train.py
```

#### Running inference:
```bash
python scripts/predict.py --audio_file path/to/audio.wav
```

#### Evaluating the model:
```bash
python scripts/evaluate.py
```

## Project Structure

```
spoken-lang-detect/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ language_classifier.py    # CNN model architecture
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ dataset.py               # Data loading and preprocessing
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py               # Configuration management
â”‚   â”‚   â””â”€â”€ visualization.py        # Plotting and analysis tools
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train.py                    # Training script
â”‚   â”œâ”€â”€ evaluate.py                 # Evaluation script
â”‚   â””â”€â”€ predict.py                  # Inference script
â”œâ”€â”€ data/                           # Dataset files
â”œâ”€â”€ saved_models/                   # Trained model weights
â”œâ”€â”€ tests/                         # Unit tests
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â””â”€â”€ README.md
```

## Technical Details

### Data Processing
- **Input Format:** 40,000 amplitude measurements per 5-second clip
- **Sampling Rate:** 8kHz
- **Normalization:** Z-score normalization applied to prevent overfitting
- **Data Augmentation:** Available for improved generalization

### Model Architecture Details
```python
Input: [batch_size, 1, 40000]
â”œâ”€â”€ Conv1d(1â†’32, kernel=50, stride=5) + ReLU + MaxPool
â”œâ”€â”€ Conv1d(32â†’64, kernel=3, stride=1) + ReLU + MaxPool  
â”œâ”€â”€ Conv1d(64â†’128, kernel=3, stride=1) + ReLU + MaxPool
â”œâ”€â”€ Conv1d(128â†’256, kernel=3, stride=1) + ReLU + MaxPool
â”œâ”€â”€ AdaptiveAvgPool1d(1)
â”œâ”€â”€ Flatten + Dropout(0.5)
â”œâ”€â”€ Linear(256â†’128â†’64â†’6)
â””â”€â”€ Output: [batch_size, 6]
```

### Training Configuration
- **Loss Function:** CrossEntropyLoss
- **Optimizer:** Adam (lr=0.001)
- **Batch Size:** 1 (due to memory constraints)
- **Epochs:** 60
- **Device:** CUDA if available, CPU otherwise

## Results & Analysis

### Confusion Matrix
The model shows good performance distinguishing between Germanic and Romance language families, with some expected confusion between linguistically similar languages.

### PCA Visualization
The model's output space demonstrates logical clustering of languages by linguistic families when visualized using Principal Component Analysis.

## Limitations & Bias

**Data Source:** The dataset was mined from YouTube videos using language-specific searches.

**Potential Biases:**
- Geographic/accent variations not well represented
- Speaker demographics may be skewed
- Audio quality variations from YouTube compression
- Topic/content bias from search methodology

**Use Case Limitations:**
- Model may perform poorly on accents not represented in training data
- Performance may degrade on non-native speakers
- Audio quality must be similar to training data (8kHz, clear speech)

## Authors

- Group 21 - Introduction to Deep Learning Course 2023

## ğŸ™ Acknowledgments

- Course instructors: Juan Sebastian Olier Jauregui, Dimitar Shterionov, and Cascha van Wanrooij